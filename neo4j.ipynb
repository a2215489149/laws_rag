{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每列的 NaN 值數量:\n",
      "LawLevel           0\n",
      "ArticleNo          0\n",
      "ArticleContent    10\n",
      "dtype: int64\n",
      "\n",
      "含有 NaN 值的行:\n",
      "    LawLevel ArticleNo ArticleContent\n",
      "91        刑法      第92條            NaN\n",
      "118       刑法     第119條            NaN\n",
      "235       刑法     第236條            NaN\n",
      "244       刑法     第245條            NaN\n",
      "286       刑法     第287條            NaN\n",
      "307       刑法     第308條            NaN\n",
      "318       刑法     第319條            NaN\n",
      "337       刑法     第338條            NaN\n",
      "342       刑法     第343條            NaN\n",
      "356       刑法     第357條            NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 讀取 CSV 文件\n",
    "csv_path = \"C:/PYTHON/國科會/csv_json/刑法.csv\"\n",
    "df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "\n",
    "# 檢查每列的 NaN 值數量\n",
    "nan_count = df.isna().sum()\n",
    "\n",
    "# 顯示有 NaN 值的列及其數量\n",
    "print(\"每列的 NaN 值數量:\")\n",
    "print(nan_count)\n",
    "\n",
    "# 顯示有 NaN 值的行\n",
    "nan_rows = df[df.isna().any(axis=1)]\n",
    "print(\"\\n含有 NaN 值的行:\")\n",
    "print(nan_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sheng\\AppData\\Local\\Temp\\ipykernel_16940\\3256547511.py:67: DeprecationWarning: write_transaction has been renamed to execute_write\n",
      "  session.write_transaction(import_data, row)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "數據插入完成！\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "# 設定 Neo4j 連線\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"\"\n",
    "password = \"\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# 使用 OpenAI 生成文本向量的函數\n",
    "os.environ['AzureOpenAIEmbeddings_KEY'] = \"\"\n",
    "os.environ[\"AzureOpenAIEmbeddings_ENDPOINT\"] = \"\"\n",
    "os.environ['AzureChatOpenAI_KEY'] = \"\"\n",
    "os.environ[\"AzureChatOpenAI_ENDPOINT\"] = \"\"\n",
    "# 初始化 Azure OpenAI Embedding 和 Chat 服務\n",
    "embedding_model = AzureOpenAIEmbeddings(\n",
    "    api_key=os.environ['AzureOpenAIEmbeddings_KEY'],  # 設定 Azure API 金鑰\n",
    "    api_version=\"2023-05-15\",  # 設定 Azure API 版本\n",
    "    model=\"text-embedding-ada-002\",  # 設定模型名稱\n",
    "    azure_endpoint=os.environ['AzureOpenAIEmbeddings_ENDPOINT']  # 設定 Azure 端點\n",
    ")\n",
    "\n",
    "# 使用 Azure OpenAI 生成文本向量\n",
    "def generate_vector(text: str):\n",
    "    \"\"\"使用 Azure OpenAI 生成文本的向量\"\"\"\n",
    "    # 生成文本的向量\n",
    "    vector = embedding_model.embed_query(text)  # 使用 embed_query 生成向量\n",
    "    return vector\n",
    "\n",
    "# 定義數據插入函數\n",
    "def import_data(tx, row):\n",
    "    # 生成 Article 節點的向量\n",
    "    article_vector = generate_vector(row['ArticleContent'])\n",
    "    \n",
    "    # 分割 CKIP Text 並對每個詞生成向量\n",
    "    words = row['CKIP Text'].split(\"||\")\n",
    "    word_vectors = {word: generate_vector(word) for word in words}\n",
    "\n",
    "    # 插入數據到 Neo4j\n",
    "    query = \"\"\"\n",
    "    MERGE (law:Law {name: \"刑法\"})\n",
    "    MERGE (article:Article {number: $ArticleNo, content: $ArticleContent, vector: $article_vector})\n",
    "    MERGE (law)-[:Include]->(article)\n",
    "    WITH article, $word_data AS word_data\n",
    "    UNWIND word_data AS word_map\n",
    "    MERGE (ckip:CKIP {text: word_map.word})\n",
    "    SET ckip.vector = word_map.vector\n",
    "    MERGE (ckip)-[:belong]->(article)\n",
    "    \"\"\"\n",
    "    \n",
    "    # 將詞彙及其向量作為參數傳遞給查詢\n",
    "    tx.run(query, \n",
    "           ArticleNo=row['ArticleNo'], \n",
    "           ArticleContent=row['ArticleContent'], \n",
    "           article_vector=article_vector,\n",
    "           word_data=[{'word': word, 'vector': vector} for word, vector in word_vectors.items()])\n",
    "\n",
    "# 讀取本地 CSV 文件\n",
    "csv_path = r\"C:\\PYTHON\\自主學習\\csv_json\\刑法_去除停用詞.csv\"\n",
    "df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
    "\n",
    "# 將數據逐行寫入 Neo4j\n",
    "with driver.session() as session:\n",
    "    for index, row in df.iterrows():\n",
    "        session.write_transaction(import_data, row)\n",
    "\n",
    "print(\"數據插入完成！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
